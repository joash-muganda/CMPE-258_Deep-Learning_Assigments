{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Learning Rate Scheduler**"
      ],
      "metadata": {
        "id": "aJKzcZAvvmiF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0LKS1HPWvijr",
        "outputId": "14235862-c5a2-4ad0-9898-76a02becfbe9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "32/32 [==============================] - 2s 6ms/step - loss: 0.1017 - lr: 0.1000\n",
            "Epoch 2/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0832 - lr: 0.1000\n",
            "Epoch 3/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0820 - lr: 0.1000\n",
            "Epoch 4/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0823 - lr: 0.1000\n",
            "Epoch 5/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0827 - lr: 0.1000\n",
            "Epoch 6/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0833 - lr: 0.1000\n",
            "Epoch 7/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0827 - lr: 0.1000\n",
            "Epoch 8/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0825 - lr: 0.1000\n",
            "Epoch 9/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0833 - lr: 0.1000\n",
            "Epoch 10/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0838 - lr: 0.1000\n",
            "Epoch 11/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0827 - lr: 0.0500\n",
            "Epoch 12/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0821 - lr: 0.0500\n",
            "Epoch 13/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0819 - lr: 0.0500\n",
            "Epoch 14/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0813 - lr: 0.0500\n",
            "Epoch 15/50\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0813 - lr: 0.0500\n",
            "Epoch 16/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0830 - lr: 0.0500\n",
            "Epoch 17/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0815 - lr: 0.0500\n",
            "Epoch 18/50\n",
            "32/32 [==============================] - 0s 12ms/step - loss: 0.0819 - lr: 0.0500\n",
            "Epoch 19/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0829 - lr: 0.0500\n",
            "Epoch 20/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0821 - lr: 0.0500\n",
            "Epoch 21/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0818 - lr: 0.0250\n",
            "Epoch 22/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0824 - lr: 0.0250\n",
            "Epoch 23/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0817 - lr: 0.0250\n",
            "Epoch 24/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0820 - lr: 0.0250\n",
            "Epoch 25/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0822 - lr: 0.0250\n",
            "Epoch 26/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0816 - lr: 0.0250\n",
            "Epoch 27/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0821 - lr: 0.0250\n",
            "Epoch 28/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0820 - lr: 0.0250\n",
            "Epoch 29/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0822 - lr: 0.0250\n",
            "Epoch 30/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0818 - lr: 0.0250\n",
            "Epoch 31/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0820 - lr: 0.0125\n",
            "Epoch 32/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0816 - lr: 0.0125\n",
            "Epoch 33/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0817 - lr: 0.0125\n",
            "Epoch 34/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0818 - lr: 0.0125\n",
            "Epoch 35/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0816 - lr: 0.0125\n",
            "Epoch 36/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0818 - lr: 0.0125\n",
            "Epoch 37/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0816 - lr: 0.0125\n",
            "Epoch 38/50\n",
            "32/32 [==============================] - 0s 8ms/step - loss: 0.0815 - lr: 0.0125\n",
            "Epoch 39/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0822 - lr: 0.0125\n",
            "Epoch 40/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0820 - lr: 0.0125\n",
            "Epoch 41/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0817 - lr: 0.0063\n",
            "Epoch 42/50\n",
            "32/32 [==============================] - 0s 11ms/step - loss: 0.0818 - lr: 0.0063\n",
            "Epoch 43/50\n",
            "32/32 [==============================] - 0s 9ms/step - loss: 0.0818 - lr: 0.0063\n",
            "Epoch 44/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0816 - lr: 0.0063\n",
            "Epoch 45/50\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.0816 - lr: 0.0063\n",
            "Epoch 46/50\n",
            "32/32 [==============================] - 0s 6ms/step - loss: 0.0816 - lr: 0.0063\n",
            "Epoch 47/50\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 0.0817 - lr: 0.0063\n",
            "Epoch 48/50\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0817 - lr: 0.0063\n",
            "Epoch 49/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0815 - lr: 0.0063\n",
            "Epoch 50/50\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.0817 - lr: 0.0063\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Generate synthetic data\n",
        "np.random.seed(0)\n",
        "x_train = np.random.random((1000, 10))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "def step_decay_schedule(initial_lr, decay_factor, step_size):\n",
        "    '''\n",
        "    Wrapper function to create a LearningRateScheduler with step decay schedule.\n",
        "    '''\n",
        "    def schedule(epoch):\n",
        "        new_lr = initial_lr * (decay_factor ** (epoch // step_size))\n",
        "        return new_lr\n",
        "\n",
        "    return keras.callbacks.LearningRateScheduler(schedule)\n",
        "\n",
        "# Model definition\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "initial_learning_rate = 0.1\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
        "              loss='mse')\n",
        "\n",
        "# Training parameters\n",
        "epochs = 50\n",
        "decay_factor = 0.5\n",
        "step_size = 10\n",
        "\n",
        "# Include the learning rate scheduler callback\n",
        "lr_scheduler = step_decay_schedule(initial_lr=initial_learning_rate,\n",
        "                                   decay_factor=decay_factor, step_size=step_size)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(x_train, y_train, epochs=epochs, callbacks=[lr_scheduler])\n",
        "\n",
        "# Optionally, plot the learning rate progress\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['lr'])\n",
        "plt.title('Learning Rate Schedule')\n",
        "plt.ylabel('Learning Rate')\n",
        "plt.xlabel('Epoch')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **custom dropout layer**"
      ],
      "metadata": {
        "id": "YKdBhomNw2qU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class VariableDropout(keras.layers.Layer):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super(VariableDropout, self).__init__(**kwargs)\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if 0. < self.rate < 1.:\n",
        "            if training:\n",
        "                return tf.nn.dropout(inputs, rate=self.rate)\n",
        "            return inputs\n",
        "        return inputs\n",
        "\n",
        "# Model definition using the custom dropout\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    VariableDropout(rate=0.5),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Generate synthetic data\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "x_train = np.random.random((1000, 10))\n",
        "y_train = np.random.random((1000, 1))\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "history = model.fit(x_train, y_train, epochs=30)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "loss = model.evaluate(x_train, y_train)\n",
        "print(\"Loss:\", loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HqgBFuew3H6",
        "outputId": "511579dc-0fd2-4ee6-9260-28abe80d64e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "32/32 [==============================] - 2s 6ms/step - loss: 0.2412\n",
            "Epoch 2/30\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1759\n",
            "Epoch 3/30\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1423\n",
            "Epoch 4/30\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 0.1237\n",
            "Epoch 5/30\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1123\n",
            "Epoch 6/30\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1068\n",
            "Epoch 7/30\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.1060\n",
            "Epoch 8/30\n",
            "32/32 [==============================] - 0s 4ms/step - loss: 0.1052\n",
            "Epoch 9/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0954\n",
            "Epoch 10/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0963\n",
            "Epoch 11/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0931\n",
            "Epoch 12/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0980\n",
            "Epoch 13/30\n",
            "32/32 [==============================] - 0s 3ms/step - loss: 0.0933\n",
            "Epoch 14/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0907\n",
            "Epoch 15/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0941\n",
            "Epoch 16/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0888\n",
            "Epoch 17/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0916\n",
            "Epoch 18/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0913\n",
            "Epoch 19/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0883\n",
            "Epoch 20/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0884\n",
            "Epoch 21/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0876\n",
            "Epoch 22/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0879\n",
            "Epoch 23/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0870\n",
            "Epoch 24/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0864\n",
            "Epoch 25/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0856\n",
            "Epoch 26/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0872\n",
            "Epoch 27/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0853\n",
            "Epoch 28/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0862\n",
            "Epoch 29/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0836\n",
            "Epoch 30/30\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.0836\n",
            "32/32 [==============================] - 0s 1ms/step - loss: 0.0791\n",
            "Loss: 0.07911263406276703\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Batch Normalization**"
      ],
      "metadata": {
        "id": "xgiJQRAXxgiQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class BatchRenormalization(keras.layers.Layer):\n",
        "    def __init__(self, momentum=0.99, epsilon=1e-3):\n",
        "        super(BatchRenormalization, self).__init__()\n",
        "        self.momentum = momentum\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.gamma = self.add_weight(shape=(input_shape[-1],), initializer=\"ones\", trainable=True)\n",
        "        self.beta = self.add_weight(shape=(input_shape[-1],), initializer=\"zeros\", trainable=True)\n",
        "        self.running_mean = self.add_weight(shape=(input_shape[-1],), initializer=\"zeros\", trainable=False)\n",
        "        self.running_variance = self.add_weight(shape=(input_shape[-1],), initializer=\"ones\", trainable=False)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if training:\n",
        "            mean, variance = tf.nn.moments(inputs, axes=[0, 1, 2], keepdims=False)\n",
        "            self.running_mean.assign(self.momentum * self.running_mean + (1 - self.momentum) * mean)\n",
        "            self.running_variance.assign(self.momentum * self.running_variance + (1 - self.momentum) * variance)\n",
        "            normed = (inputs - mean) / tf.sqrt(variance + self.epsilon)\n",
        "        else:\n",
        "            normed = (inputs - self.running_mean) / tf.sqrt(self.running_variance + self.epsilon)\n",
        "        return self.gamma * normed + self.beta\n",
        "\n",
        "# Generate synthetic data\n",
        "x_train = np.random.rand(1000, 28, 28, 1).astype('float32')  # 1000 samples of 28x28 pixels, grayscale images\n",
        "y_train = np.random.randint(0, 10, size=(1000,)).astype('int32')  # 1000 labels for 10 classes\n",
        "\n",
        "# Example of using the Batch Renormalization layer in a model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    BatchRenormalization(),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "metrics = model.evaluate(x_train, y_train)\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84J6YwQZxkXs",
        "outputId": "eb671bf7-3128-471e-d1ac-e91a915683e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 4s 47ms/step - loss: 3.1276 - accuracy: 0.1080\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 2.0896 - accuracy: 0.2680\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 1s 30ms/step - loss: 1.2953 - accuracy: 0.5930\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.6102 - accuracy: 0.8950\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 1s 27ms/step - loss: 0.2674 - accuracy: 0.9860\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.1254 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 1s 28ms/step - loss: 0.0694 - accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 1s 29ms/step - loss: 0.0462 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 1s 40ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 1s 44ms/step - loss: 0.0265 - accuracy: 1.0000\n",
            "32/32 [==============================] - 0s 7ms/step - loss: 1.1379 - accuracy: 1.0000\n",
            "Metrics: [1.137925386428833, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom dropout**"
      ],
      "metadata": {
        "id": "N097nBXSyq16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class CustomDropout(keras.layers.Layer):\n",
        "    def __init__(self, rate, **kwargs):\n",
        "        super(CustomDropout, self).__init__(**kwargs)\n",
        "        self.rate = rate\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        if training:\n",
        "            noise_shape = (tf.shape(inputs)[0], 1, 1, tf.shape(inputs)[3])\n",
        "            return tf.nn.dropout(inputs, rate=self.rate, noise_shape=noise_shape)\n",
        "        return inputs\n",
        "\n",
        "# Example of using the Custom Dropout layer in a model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "    CustomDropout(0.5),\n",
        "    keras.layers.MaxPooling2D(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Generate synthetic data\n",
        "x_train = np.random.rand(1000, 28, 28, 1).astype('float32')  # 1000 samples of 28x28 pixels, grayscale images\n",
        "y_train = np.random.randint(0, 10, size=(1000,)).astype('int32')  # 1000 labels for 10 classes\n",
        "\n",
        "# Compile and train the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=10)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "metrics = model.evaluate(x_train, y_train)\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbr6o8ObymZc",
        "outputId": "2e03ac43-ac08-492d-887f-c6b020b659f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 2.3701 - accuracy: 0.1130\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 1s 15ms/step - loss: 2.2933 - accuracy: 0.1140\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 2.2597 - accuracy: 0.1690\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 2.2130 - accuracy: 0.2470\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 2.1647 - accuracy: 0.2400\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 2.1081 - accuracy: 0.3410\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 2.0296 - accuracy: 0.3820\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.9753 - accuracy: 0.4060\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 15ms/step - loss: 1.9148 - accuracy: 0.4450\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 1s 16ms/step - loss: 1.8049 - accuracy: 0.5240\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 1.6950 - accuracy: 0.8070\n",
            "Metrics: [1.695030927658081, 0.8069999814033508]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Loss Function: Huber Loss**"
      ],
      "metadata": {
        "id": "Q7p5qXhBzXbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class HuberLoss(keras.losses.Loss):\n",
        "    def __init__(self, threshold=1.0):\n",
        "        super(HuberLoss, self).__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        error = y_true - y_pred\n",
        "        is_small_error = tf.abs(error) <= self.threshold\n",
        "        squared_loss = tf.square(error) / 2\n",
        "        linear_loss = self.threshold * (tf.abs(error) - self.threshold / 2)\n",
        "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
        "\n",
        "# Example of using the custom Huber loss in a model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, activation='relu', input_shape=(10,)),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss=HuberLoss(2.0))\n",
        "\n",
        "# Generate synthetic data\n",
        "x_train = tf.random.normal((100, 10))\n",
        "y_train = 2 * x_train[:, 0] + 3 * x_train[:, 1] + 1 + tf.random.normal((100,))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, verbose=1)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "metrics = model.evaluate(x_train, y_train)\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vu_svsNyzcYQ",
        "outputId": "0c9f7fb5-7180-4725-8eae-1576df01c301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 4.9081\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.8121\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.7286\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.6462\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.5709\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.4952\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.4131\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.3379\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 4.2588\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 4.1780\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 4.1169\n",
            "Metrics: 4.116886615753174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Activation Function: Parametric SoftPlus**"
      ],
      "metadata": {
        "id": "BLusD5NSzoxn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "class ParametricSoftPlus(keras.layers.Layer):\n",
        "    def __init__(self, beta=1.0):\n",
        "        super(ParametricSoftPlus, self).__init__()\n",
        "        self.beta = beta  # Parameter to control the steepness\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return tf.math.log(1.0 + tf.math.exp(self.beta * inputs))\n",
        "\n",
        "# Example of using the custom Parametric SoftPlus activation in a model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, input_shape=(10,)),\n",
        "    ParametricSoftPlus(beta=0.5),  # Using a custom activation function\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Generate synthetic data\n",
        "x_train = tf.random.normal((100, 10))\n",
        "y_train = 2 * x_train[:, 0] + 3 * x_train[:, 1] + 1 + tf.random.normal((100,))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, verbose=1)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "metrics = model.evaluate(x_train, y_train)\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJrNRNt-zuFi",
        "outputId": "c1fc8670-dc04-4693-d0e1-1c489c812d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 13.0747\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.8824\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.7200\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.5411\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 12.4179\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 12.2730\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.1469\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.0085\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 11.9244\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 11.7805\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 11.6863\n",
            "Metrics: 11.686280250549316\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Initializer: Random Normal Multiplier**"
      ],
      "metadata": {
        "id": "x50xXZPSz_Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomNormalMultiplier(keras.initializers.Initializer):\n",
        "    def __init__(self, mean=0.0, stddev=0.05, multiplier=1.0):\n",
        "        self.mean = mean\n",
        "        self.stddev = stddev\n",
        "        self.multiplier = multiplier\n",
        "\n",
        "    def __call__(self, shape, dtype=None):\n",
        "        return tf.random.normal(shape, mean=self.mean, stddev=self.stddev, dtype=dtype) * self.multiplier\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'mean': self.mean, 'stddev': self.stddev, 'multiplier': self.multiplier}\n"
      ],
      "metadata": {
        "id": "EE5Ckxkc0Dvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Regularizer: L2 Regularization with Scaling**"
      ],
      "metadata": {
        "id": "je23D77L0M_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class L2RegularizerWithScale(keras.regularizers.Regularizer):\n",
        "    def __init__(self, scale=0.01):\n",
        "        self.scale = scale\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.scale * tf.reduce_sum(tf.square(x))\n",
        "\n",
        "    def get_config(self):\n",
        "        return {'scale': self.scale}\n"
      ],
      "metadata": {
        "id": "X3KegTjD0PvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using Custom Initializer and Regularizer in a Model**"
      ],
      "metadata": {
        "id": "vytFq_z30TQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(64, input_shape=(10,),\n",
        "                       kernel_initializer=RandomNormalMultiplier(multiplier=2.0),\n",
        "                       kernel_regularizer=L2RegularizerWithScale(scale=0.02)),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Generate synthetic data\n",
        "x_train = tf.random.normal((100, 10))\n",
        "y_train = 2 * x_train[:, 0] + 3 * x_train[:, 1] + 1 + tf.random.normal((100,))\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, verbose=1)\n",
        "\n",
        "# Optionally, evaluate the model\n",
        "metrics = model.evaluate(x_train, y_train)\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztTGm9eK0V8s",
        "outputId": "2a7fe634-9470-423f-b29a-bda94bedd3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 14.4623\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 14.0040\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 13.6130\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 13.2286\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.8613\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.4864\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.1157\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 11.7722\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 11.4487\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 11.1255\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 10.8870\n",
            "Metrics: 10.887018203735352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Custom Metric: Precision**"
      ],
      "metadata": {
        "id": "HJtHTT5i0qyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Precision(keras.metrics.Metric):\n",
        "    def __init__(self, name='precision', **kwargs):\n",
        "        super(Precision, self).__init__(name=name, **kwargs)\n",
        "        self.true_positives = self.add_weight(name='tp', initializer='zeros')\n",
        "        self.predicted_positives = self.add_weight(name='pp', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        y_pred = tf.round(y_pred)\n",
        "        true_pos = tf.equal(y_true, 1) & tf.equal(y_pred, 1)\n",
        "        true_pos = tf.cast(true_pos, self.dtype)\n",
        "        pred_pos = tf.cast(tf.equal(y_pred, 1), self.dtype)\n",
        "\n",
        "        self.true_positives.assign_add(tf.reduce_sum(true_pos))\n",
        "        self.predicted_positives.assign_add(tf.reduce_sum(pred_pos))\n",
        "\n",
        "    def result(self):\n",
        "        precision = self.true_positives / (self.predicted_positives + tf.keras.backend.epsilon())\n",
        "        return precision\n",
        "\n",
        "    def reset_states(self):\n",
        "        self.true_positives.assign(0)\n",
        "        self.predicted_positives.assign(0)\n"
      ],
      "metadata": {
        "id": "WdD3mtx40u-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Using the Custom Metric in a Model**"
      ],
      "metadata": {
        "id": "r8XRL2K70ysR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[Precision()])\n",
        "\n",
        "# Generate synthetic binary classification data\n",
        "x_train = tf.random.normal((100, 10))\n",
        "y_train = tf.cast(tf.random.uniform((100,)) > 0.5, tf.float32)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, verbose=1)\n",
        "\n",
        "# Optionally, evaluate the model using custom precision metric\n",
        "metrics = model.evaluate(x_train, y_train)\n",
        "print(\"Metrics:\", metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlW84-by00zb",
        "outputId": "5c1a9849-73dd-4cd6-a330-22baca298e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 1s 7ms/step - loss: 0.7881 - precision: 0.4474\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7809 - precision: 0.4474\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7753 - precision: 0.4595\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7703 - precision: 0.4595\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7656 - precision: 0.4595\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7613 - precision: 0.4595\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7575 - precision: 0.4737\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7538 - precision: 0.4737\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 0.7502 - precision: 0.4737\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:2723: UserWarning: Metric Precision implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
            "  m.reset_state()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7467 - precision: 0.4737\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7439 - precision: 0.4737\n",
            "Metrics: [0.7439082860946655, 0.4736842215061188]\n"
          ]
        }
      ]
    }
  ]
}