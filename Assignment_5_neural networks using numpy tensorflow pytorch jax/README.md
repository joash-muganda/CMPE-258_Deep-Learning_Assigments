# Exploring Basic Neural Networks with NumPy, TensorFlow, PyTorch, and JAX

This project delves into the basics of neural network architectures, showcasing their implementation and functionality across various popular libraries: NumPy, TensorFlow, PyTorch, and JAX. Each library offers unique approaches and utilities for neural network development, from low-level operations to high-level APIs. The project is organized into 13 notebooks, each tailored to demonstrate specific aspects and capabilities of these libraries in the context of simple neural network models.

## Project Overview

The primary goal of this project is to compare and contrast how basic neural networks can be implemented and managed across different programming environments. It serves as an educational toolkit for understanding the syntactical and conceptual differences among the libraries.

## Video Explanation

For an in-depth explanation of the project, including a discussion on the design choices and insights gained from using each library, please watch the accompanying video presentation: [Watch the video](https://drive.google.com/example_video_link)

## Notebooks

Here is a brief overview of what each notebook covers:

1. **NumPy Neural Network**: Starting with the basics, this notebook uses NumPy to manually implement a neural network, offering a foundational understanding of neural computations. [View Notebook](https://example.com/numpy_neural_network)
2. **TensorFlow Neural Network**: This set of notebooks explores TensorFlow's capabilities, from low-level operations using `tf.Module` to high-level abstractions with `tf.keras.Model`. 
    - Low-Level TensorFlow [View Notebook](https://example.com/tf_low_level)
    - TensorFlow with Keras Sequential API [View Notebook](https://example.com/tf_keras_sequential)
    - TensorFlow Functional API [View Notebook](https://example.com/tf_functional_api)
3. **PyTorch Neural Network**: Similar to TensorFlow, these notebooks demonstrate neural network implementations in PyTorch, showcasing both manual implementations and the use of `torch.nn.Module`.
    - Basic PyTorch [View Notebook](https://example.com/pytorch_basic)
    - PyTorch with `torch.nn` [View Notebook](https://example.com/pytorch_torch_nn)
    - PyTorch Lightning [View Notebook](https://example.com/pytorch_lightning)
4. **JAX Neural Network**: JAX notebooks highlight the use of this library for both manual neural network computations and the application of the Flax library for more abstracted network definitions.
    - Basic JAX [View Notebook](https://example.com/jax_basic)
    - JAX with Flax [View Notebook](https://example.com/jax_with_flax)

(Additional descriptions and placeholders for the remaining notebooks)

## Getting Started

To dive into the notebooks, clone this repository, and follow the installation instructions in each notebook to set up the required environments. Whether you're a seasoned machine learning practitioner or new to neural networks, these notebooks provide valuable insights into the landscape of neural network programming in Python.

## Contributing

Feedback and contributions are welcome! If you have suggestions or want to contribute additional examples or improvements, please feel free to submit an issue or pull request.

## License

This project is open-sourced under the MIT License. See the LICENSE file for more details.
