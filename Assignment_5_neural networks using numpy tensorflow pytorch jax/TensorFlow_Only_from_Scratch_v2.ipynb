{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_data(num_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    x = np.random.uniform(-2, 2, num_samples)\n",
        "    y = np.random.uniform(-2, 2, num_samples)\n",
        "    z = np.random.uniform(-2, 2, num_samples)\n",
        "    f_xyz = np.sin(x) + np.cos(y) * np.power(z, 2)\n",
        "    features = np.vstack((x, y, z)).T\n",
        "    outputs = f_xyz\n",
        "    return features, outputs\n"
      ],
      "metadata": {
        "id": "KXpRY3P-ajRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uj_qzTufZ0w8",
        "outputId": "e6f77598-3e23-46d3-e2a5-143bce023807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss = 1.9990772008895874\n",
            "Epoch 2: Loss = 1.7712515592575073\n",
            "Epoch 3: Loss = 1.683562159538269\n",
            "Epoch 4: Loss = 1.6808720827102661\n",
            "Epoch 5: Loss = 1.6830840110778809\n",
            "Epoch 6: Loss = 1.682672381401062\n",
            "Epoch 7: Loss = 1.680635690689087\n",
            "Epoch 8: Loss = 1.6825085878372192\n",
            "Epoch 9: Loss = 1.6802246570587158\n",
            "Epoch 10: Loss = 1.6806625127792358\n",
            "Epoch 11: Loss = 1.6823805570602417\n",
            "Epoch 12: Loss = 1.6777071952819824\n",
            "Epoch 13: Loss = 1.6781960725784302\n",
            "Epoch 14: Loss = 1.6761876344680786\n",
            "Epoch 15: Loss = 1.680379033088684\n",
            "Epoch 16: Loss = 1.6795252561569214\n",
            "Epoch 17: Loss = 1.6812105178833008\n",
            "Epoch 18: Loss = 1.6782373189926147\n",
            "Epoch 19: Loss = 1.681700587272644\n",
            "Epoch 20: Loss = 1.6768536567687988\n",
            "Epoch 21: Loss = 1.6787195205688477\n",
            "Epoch 22: Loss = 1.6810320615768433\n",
            "Epoch 23: Loss = 1.6808714866638184\n",
            "Epoch 24: Loss = 1.6798713207244873\n",
            "Epoch 25: Loss = 1.6777795553207397\n",
            "Epoch 26: Loss = 1.6794718503952026\n",
            "Epoch 27: Loss = 1.6774235963821411\n",
            "Epoch 28: Loss = 1.6833000183105469\n",
            "Epoch 29: Loss = 1.6785516738891602\n",
            "Epoch 30: Loss = 1.6780623197555542\n",
            "Epoch 31: Loss = 1.6803343296051025\n",
            "Epoch 32: Loss = 1.6792303323745728\n",
            "Epoch 33: Loss = 1.6777454614639282\n",
            "Epoch 34: Loss = 1.6801040172576904\n",
            "Epoch 35: Loss = 1.677187204360962\n",
            "Epoch 36: Loss = 1.6788827180862427\n",
            "Epoch 37: Loss = 1.6792165040969849\n",
            "Epoch 38: Loss = 1.6791070699691772\n",
            "Epoch 39: Loss = 1.6761616468429565\n",
            "Epoch 40: Loss = 1.6794034242630005\n",
            "Epoch 41: Loss = 1.6810165643692017\n",
            "Epoch 42: Loss = 1.6778759956359863\n",
            "Epoch 43: Loss = 1.678379774093628\n",
            "Epoch 44: Loss = 1.6830453872680664\n",
            "Epoch 45: Loss = 1.6790353059768677\n",
            "Epoch 46: Loss = 1.6775376796722412\n",
            "Epoch 47: Loss = 1.677521824836731\n",
            "Epoch 48: Loss = 1.677567481994629\n",
            "Epoch 49: Loss = 1.6809855699539185\n",
            "Epoch 50: Loss = 1.6788769960403442\n",
            "Epoch 51: Loss = 1.679878830909729\n",
            "Epoch 52: Loss = 1.6803557872772217\n",
            "Epoch 53: Loss = 1.6817713975906372\n",
            "Epoch 54: Loss = 1.6780807971954346\n",
            "Epoch 55: Loss = 1.6775742769241333\n",
            "Epoch 56: Loss = 1.680505633354187\n",
            "Epoch 57: Loss = 1.6790716648101807\n",
            "Epoch 58: Loss = 1.6819347143173218\n",
            "Epoch 59: Loss = 1.6770515441894531\n",
            "Epoch 60: Loss = 1.682722806930542\n",
            "Epoch 61: Loss = 1.6847783327102661\n",
            "Epoch 62: Loss = 1.6799756288528442\n",
            "Epoch 63: Loss = 1.677474021911621\n",
            "Epoch 64: Loss = 1.6793473958969116\n",
            "Epoch 65: Loss = 1.679316759109497\n",
            "Epoch 66: Loss = 1.676093578338623\n",
            "Epoch 67: Loss = 1.6771888732910156\n",
            "Epoch 68: Loss = 1.6777845621109009\n",
            "Epoch 69: Loss = 1.678220272064209\n",
            "Epoch 70: Loss = 1.6775693893432617\n",
            "Epoch 71: Loss = 1.6777130365371704\n",
            "Epoch 72: Loss = 1.6787511110305786\n",
            "Epoch 73: Loss = 1.6916418075561523\n",
            "Epoch 74: Loss = 1.6778401136398315\n",
            "Epoch 75: Loss = 1.6783605813980103\n",
            "Epoch 76: Loss = 1.6778538227081299\n",
            "Epoch 77: Loss = 1.677879810333252\n",
            "Epoch 78: Loss = 1.6766843795776367\n",
            "Epoch 79: Loss = 1.6768748760223389\n",
            "Epoch 80: Loss = 1.6793676614761353\n",
            "Epoch 81: Loss = 1.6775572299957275\n",
            "Epoch 82: Loss = 1.6779900789260864\n",
            "Epoch 83: Loss = 1.6796492338180542\n",
            "Epoch 84: Loss = 1.6806622743606567\n",
            "Epoch 85: Loss = 1.678502082824707\n",
            "Epoch 86: Loss = 1.6786843538284302\n",
            "Epoch 87: Loss = 1.6767706871032715\n",
            "Epoch 88: Loss = 1.6782209873199463\n",
            "Epoch 89: Loss = 1.6839288473129272\n",
            "Epoch 90: Loss = 1.6779955625534058\n",
            "Epoch 91: Loss = 1.6768810749053955\n",
            "Epoch 92: Loss = 1.6756172180175781\n",
            "Epoch 93: Loss = 1.677309274673462\n",
            "Epoch 94: Loss = 1.677013874053955\n",
            "Epoch 95: Loss = 1.6809179782867432\n",
            "Epoch 96: Loss = 1.6778688430786133\n",
            "Epoch 97: Loss = 1.6769614219665527\n",
            "Epoch 98: Loss = 1.6776092052459717\n",
            "Epoch 99: Loss = 1.6770663261413574\n",
            "Epoch 100: Loss = 1.6777454614639282\n",
            "Test Loss: 1.6410562992095947\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class ThreeLayerNN(tf.Module):\n",
        "    def __init__(self, input_size=3, hidden_size=64, output_size=1):\n",
        "        super().__init__()\n",
        "        self.W1 = tf.Variable(tf.random.normal([input_size, hidden_size], stddev=0.01))\n",
        "        self.b1 = tf.Variable(tf.zeros([hidden_size]))\n",
        "        self.W2 = tf.Variable(tf.random.normal([hidden_size, hidden_size], stddev=0.01))\n",
        "        self.b2 = tf.Variable(tf.zeros([hidden_size]))\n",
        "        self.W3 = tf.Variable(tf.random.normal([hidden_size, output_size], stddev=0.01))\n",
        "        self.b3 = tf.Variable(tf.zeros([output_size]))\n",
        "\n",
        "    def __call__(self, X):\n",
        "        Z1 = tf.add(tf.matmul(X, self.W1), self.b1)\n",
        "        A1 = tf.nn.relu(Z1)\n",
        "        Z2 = tf.add(tf.matmul(A1, self.W2), self.b2)\n",
        "        A2 = tf.nn.relu(Z2)\n",
        "        Z3 = tf.add(tf.matmul(A2, self.W3), self.b3)\n",
        "        return Z3\n",
        "\n",
        "def compute_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "\n",
        "class ModelTrainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, X, y):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self.model(X)\n",
        "            loss = compute_loss(y, y_pred)\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    def train(self, train_dataset, num_epochs=100):\n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "            for X_batch, y_batch in train_dataset:\n",
        "                loss = self.train_step(X_batch, y_batch)\n",
        "                epoch_loss_avg.update_state(loss)\n",
        "            print(f\"Epoch {epoch + 1}: Loss = {epoch_loss_avg.result().numpy()}\")\n",
        "\n",
        "# Generate and prepare data\n",
        "features, outputs = generate_data()  # Assume this function is defined elsewhere\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, outputs, test_size=0.2, random_state=42)\n",
        "X_train_tf = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "X_test_tf = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "\n",
        "# Setup training\n",
        "model = ThreeLayerNN()\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
        "trainer = ModelTrainer(model, optimizer)\n",
        "\n",
        "# Convert training data to TensorFlow Dataset for easy batching\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_tf, y_train_tf))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "# Train the model\n",
        "trainer.train(train_dataset, num_epochs=100)\n",
        "\n",
        "# Evaluate the model\n",
        "y_pred = model(X_test_tf)\n",
        "test_loss = compute_loss(y_test_tf, y_pred)\n",
        "print(f\"Test Loss: {test_loss.numpy()}\")\n"
      ]
    }
  ]
}