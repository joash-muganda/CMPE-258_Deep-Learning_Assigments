{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Qu3XhYrOelFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqTKPZPqeQWr"
      },
      "outputs": [],
      "source": [
        "def generate_data(num_samples=1000):\n",
        "    np.random.seed(42)\n",
        "    x = np.random.uniform(-2, 2, num_samples)\n",
        "    y = np.random.uniform(-2, 2, num_samples)\n",
        "    z = np.random.uniform(-2, 2, num_samples)\n",
        "    f_xyz = np.sin(x) + np.cos(y) * np.power(z, 2)\n",
        "    features = np.vstack((x, y, z)).T\n",
        "    outputs = f_xyz\n",
        "    return features, outputs\n",
        "\n",
        "features, outputs = generate_data()  # Generates synthetic dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Low-Level API**"
      ],
      "metadata": {
        "id": "nnCGZnZsfUsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class CustomNNLowLevel(tf.Module):\n",
        "    def __init__(self, input_size=3, hidden_size=64, output_size=1):\n",
        "        super().__init__()\n",
        "        # Initialize weights and biases using low-level TensorFlow operations\n",
        "        self.W1 = tf.Variable(tf.random.truncated_normal([input_size, hidden_size], stddev=0.1))\n",
        "        self.b1 = tf.Variable(tf.zeros([hidden_size]))\n",
        "        self.W2 = tf.Variable(tf.random.truncated_normal([hidden_size, hidden_size], stddev=0.1))\n",
        "        self.b2 = tf.Variable(tf.zeros([hidden_size]))\n",
        "        self.W3 = tf.Variable(tf.random.truncated_normal([hidden_size, output_size], stddev=0.1))\n",
        "        self.b3 = tf.Variable(tf.zeros([output_size]))\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x = tf.add(tf.matmul(x, self.W1), self.b1)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.add(tf.matmul(x, self.W2), self.b2)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = tf.add(tf.matmul(x, self.W3), self.b3)\n",
        "        return x\n",
        "\n",
        "# Assume generate_data() is defined as shown previously\n",
        "features, outputs = generate_data(1000) # Generate synthetic data\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, outputs, test_size=0.2, random_state=42)\n",
        "\n",
        "# Training process similar to previous examples, using CustomNNLowLevel and manual gradients\n",
        "\n"
      ],
      "metadata": {
        "id": "oYCec8juecRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "def train_step(model, inputs, outputs, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        current_loss = tf.reduce_mean(tf.square(model(inputs) - outputs))\n",
        "    gradients = tape.gradient(current_loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return current_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "K439ZHhte2r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X_train, y_train, optimizer, epochs=100):\n",
        "    for epoch in range(epochs):\n",
        "        loss = train_step(model, X_train, y_train, optimizer)\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch}: Loss: {loss.numpy()}\")\n",
        "\n",
        "# Convert data to tensors\n",
        "X_train_tf = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "y_train_tf = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
        "\n",
        "# Initialize the model and start training\n",
        "model = CustomNNLowLevel()\n",
        "train(model, X_train_tf, y_train_tf, optimizer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUrtY2jNfFyc",
        "outputId": "4515af17-32f3-4f31-fc8e-9e4400ffed72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss: 2.011073350906372\n",
            "Epoch 10: Loss: 1.7068597078323364\n",
            "Epoch 20: Loss: 1.6846498250961304\n",
            "Epoch 30: Loss: 1.6806187629699707\n",
            "Epoch 40: Loss: 1.6788954734802246\n",
            "Epoch 50: Loss: 1.6771711111068726\n",
            "Epoch 60: Loss: 1.6765714883804321\n",
            "Epoch 70: Loss: 1.6763465404510498\n",
            "Epoch 80: Loss: 1.6762698888778687\n",
            "Epoch 90: Loss: 1.6762449741363525\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, X_test, y_test):\n",
        "    X_test_tf = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "    y_test_tf = tf.convert_to_tensor(y_test, dtype=tf.float32)\n",
        "    predictions = model(X_test_tf)\n",
        "    mse_loss = tf.reduce_mean(tf.square(predictions - y_test_tf))\n",
        "    print(f\"Test MSE: {mse_loss.numpy()}\")\n",
        "\n",
        "evaluate(model, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pIR2Vg3fLrB",
        "outputId": "cf1fc911-642f-42e6-f1f0-0d96cbdd23c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test MSE: 1.6408116817474365\n"
          ]
        }
      ]
    }
  ]
}